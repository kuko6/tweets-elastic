# PDT protokol 5

Jakub Povinec

[https://github.com/kuko6/tweets-elastic](https://github.com/kuko6/tweets-elastic)

----

(tento protokol som p√≠sal ako markdown a teda export do pdf nie je ide√°lny. Odpor√∫ƒçam rad≈°ej origin√°l, ktor√Ω je v `docs/protokol.md` a taktie≈æ aj na [githube](https://github.com/kuko6/tweets-elastic/blob/main/docs/protokol.md))

## √öloha 1

Elasticsearch som sp√∫≈°≈•al pomocou dockeru, resp. `docker compose`, kde konfigur√°cia jednotliv√Ωch in≈°tanci√≠/kontajnerov elasticu je obsiahnut√° v s√∫bore `docker-compose.yml` . In≈°tancie elasticu sa daj√∫ spusti≈• pomocou pr√≠kazu `docker compose up` a vypn√∫≈• pomocou `docker compose down` alebo postupne, napr. pomocou `docker stop [n√°zov kontajnera]`

Stav jednotliv√Ωch in≈°tanci√≠ sa d√° overi≈• pomocou `GET http://localhost:9200/_cat/nodes?v`

![SniÃÅmka obrazovky 2022-12-21 o 22.07.46.png](https://res.craft.do/user/full/c3363b00-79de-4d25-d963-64ad0ea4e431/083EADBD-AC79-422F-98FF-5EED1CADF57B_2/A47BIXWqwxcxRjW5EcOonnThyQ8MQW2bb7q6UJ9vUmcz/Snimka%20obrazovky%202022-12-21%20o%2022.07.46.png)

*Fig. 1 Stav jednotliv√Ωch elastic in≈°tanci√≠*

## √öloha 2

Optim√°lny poƒçet shardov v elasticu z√°le≈æ√≠ na poƒçte nodov, veƒækosti indexovan√Ωch d√°t a taktie≈æ dostupn√Ωch zdrojov (CPU a pam√§te). Shardy umo≈æ≈àuj√∫ paraleliz√°ciu dopytov s t√Ωm, ≈æe rozdelia indexovan√© d√°ta medzi jednotliv√© nody. Najide√°lnej≈°ie je teda, aby bol poƒçet shardov deliteƒæn√Ω poƒçtom nodov, kedy by sa shardy vedeli rovnomerne rozdeli≈• medzi jednotliv√© nody. Podƒæa tohto ƒçl√°nku ([How many shards should I have in my Elasticsearch cluster?](https://www.elastic.co/blog/how-many-shards-should-i-have-in-my-elasticsearch-cluster)), by mal ma≈• shard velkos≈• okolo 20 a≈æ 40GB. V na≈°om pr√≠pade maj√∫ d√°ta zhruba 70-80GB a teda ide√°lny poƒçet shardov je buƒè 3 alebo 6. Aj keƒè je v√§ƒç≈°√≠ poƒçet shardov efekt√≠vnej≈°√≠ z hƒæadiska r√Ωchlosti dopytov, ka≈æd√Ω shard si mus√≠ uchov√°va≈• e≈°te dodatoƒçn√© inform√°cie o ulo≈æen√Ωch d√°tach, kde pri men≈°om poƒçte shardov m√¥≈æe by≈• tento "overhead" v√Ωrazne men≈°√≠. Keƒè≈æe je pri tomto zadan√≠ m√¥j najv√§ƒç≈°√≠ probl√©m hlavne nedostatok voƒæn√©ho miesta, zvolil som rad≈°ej **men≈°√≠ poƒçet shardov 3**.

Repliky zas predstavuj√∫ k√≥pie jednotliv√Ωch shardov. Repliky s√∫ v≈ædy na inom node ako prim√°rne shardy a sl√∫≈æia na nahradenie dan√©ho shardu v pr√≠pade, ak node na ktorom sa nach√°dza vypadne. Ide√°lne je ma≈• v≈ædy aspo≈à jednu repliku pre ka≈æd√Ω shard.

Poƒçet shardov a nodov sa zad√°va pri vytv√°ran√≠ indexu pomocou `PUT http://localhost:9200/tweets`

```json
{
	"settings": {
		"index": {
			"number_of_shards": 3,
			"number_of_replicas": 1
		},
}
```

*Fig. 2 ≈†pecifikovanie poƒçtu shardov a repl√≠k pri vytv√°ran√≠ indexu*

V na≈°om pr√≠pade bolo fin√°lne rozdelenie shardov a repl√≠k nasledovn√©:

![SniÃÅmka obrazovky 2022-12-22 o 12.33.29.png](https://res.craft.do/user/full/c3363b00-79de-4d25-d963-64ad0ea4e431/2AC63479-3C96-4453-9130-0B34F2FD777B_2/npnJ611qp3azCSthNynvF5J2zc6OnyulGPeiJnWTPSkz/Snimka%20obrazovky%202022-12-22%20o%2012.33.29.png)

*Fig. 3 Rozdelenie shardov a repl√≠k*

## √öloha 3

T√°to √∫loha je rozdelen√° na viac ƒçast√≠: vytvorenie mappingu a denormaliz√°cia d√°t z postgresql datab√°zy.

### Mapping

Pri vytv√°ran√≠ mappingu som sa sna≈æil zachova≈• podobn√∫ ≈°trukt√∫ru d√°t a tabuliek ak√° je v postgres datab√°ze s t√Ωm, ≈æe som vynechal stƒ∫pce s id z tabuliek: `context_annotations`, `conversation_hashtags` a `hashtags`, `annotations` a `links` preto≈æe sa nenach√°dzaj√∫ v [twitter dokument√°ci√≠ pre objekt tweet](https://developer.twitter.com/en/docs/twitter-api/data-dictionary/object-model/tweet) a teda mi pri≈°li zbytoƒçn√©. Cel√© mapovanie sa nach√°dza v `src/config/mapping.json`.

```json
{
    "id": { "type": "long" },
    "content": { "type": "text", "analyzer": "englando" },
    "possibly_sensitive": { "type": "boolean" },
    "language": { "type": "keyword" },
    "source": { "type": "keyword" },
    "retweet_count": { "type": "integer" },
    "reply_count": { "type": "integer" },
    "like_count": { "type": "integer" },
    "quote_count": { "type": "integer" },
    "created_at": { "type": "date", "format": "yyyy-MM-dd'T'HH:mm:ssZZZZZ" }
}
```

*Fig. 4 Mapping pre d√°ta z tabuƒæky conversations*

V mapovan√≠ d√°t pre tabuƒæku `conversations` som pre pole `content` ≈°pecifikoval vlastn√Ω analyz√©r (definovan√Ω v 4. √∫lohe). Polia `language` a `source` som zaindexoval ako `keyword`, keƒè≈æe sa zvyƒçajne jedn√° len o samotn√© slov√° alebo fr√°zy, ktor√© nemusia by≈• analyzovan√©. Taktie≈æ som definoval form√°t d√°tumu pre pole `created_at`, ktor√© zodpoved√° form√°tu v akom s√∫ d√°ta v p√¥vodnej datab√°ze.

```json
{
    "author": {
        "properties": {
            "id": { "type": "long" },
            "name": { 
                "type": "text",
                "fields": {
                    "ngram": { "type": "text", "analyzer": "custom_ngram" },
                    "shingles": { "type": "text", "analyzer": "custom_shingles" }
                } 
            },
            "username": { 
                "type": "text",
                "fields": {
                    "ngram": { "type": "text", "analyzer": "custom_ngram" }
                }  
            },
            "description": { 
                "type": "text",
                "analyzer": "englando",
                "fields": {
                    "shingles": { "type": "text", "analyzer": "custom_shingles" }
                }
            },
            "followers_count": { "type": "integer" },
            "following_count": { "type": "integer" },
            "tweet_count": { "type": "integer" },
            "listed_count": { "type": "integer" }
        }
    }
}
```

*Fig. 5 Mapping pre d√°ta z tabuƒæky authors*

Inform√°cie o autorovi s√∫ v dokumente ulo≈æen√© ako samostatn√Ω objekt `author`. Pre atrib√∫ty `name`, `username` a `description` som pridal aj dodatoƒçn√© mapovanie pre vytvoren√© analyz√©ry `custom_ngram` a `custom_shingles`.

```json
{
    "context_annotations": {
        "type": "nested",
        "properties": {
            "entity": {
                "properties": {
                    "id": { "type": "long" },
                    "name": { "type": "keyword" },
                    "description": { "type": "text", "analyzer": "englando" }
                }
            },
            "domain": {
                "properties": {
                    "id": { "type": "long" },
                    "name": { "type": "keyword" },
                    "description": { "type": "text", "analyzer": "englando" }
                }
            }
        }
    }
}
```

*Fig. 6 Mapping pre d√°ta z tabuƒæky context_annotations*

D√°ta z `context_annotations` s√∫ reprezentovan√© ako pole objektov `entity` a `domain`. Aby sa dalo dopytova≈• na jednotliv√© objekty v poli, je potrebn√© `context_annotations` indexova≈• ako `nested`.

```json
{
    "conversation_hashtags": {
        "properties": {
            "tag": { "type": "text", "analyzer":"keyword_lowercase" }
        }
    }
}
```

*Fig. 7 Mapping pre d√°ta z tabuƒæky conversation_hashtags*

Hashtagy s√∫ indexovan√© ako pole objektov, ktor√© maj√∫ atrib√∫t `tag`, reprezentuj√∫ci samotn√Ω hashtag. `Tag` je indexovan√Ω ako `text` s vlastn√Ωm analyz√°torom, ktor√Ω ich indexuje v lowercase. V tomto pr√≠pade netreba ≈°pecifikova≈• typ `nested`, keƒè≈æe objekty obsahuj√∫ len jeden atrib√∫t.

```json
{
    "annotations": {
        "type": "nested",
        "properties": {
            "value": { "type": "keyword" },
            "type": { "type": "keyword" },
            "probability": { "type": "half_float" }
        }
    },
    "links": {
        "type": "nested",
        "properties": {
            "url": { "type": "keyword" },
            "title": { "type": "keyword" },
            "description": { "type": "keyword" }
        }
    }
}
```

*Fig. 8 Mapping pre d√°ta z tabuliek annotations a links*

Mapovanie tabuliek `annotations` a `links` je viacmenej rovnak√©, kde obe tabuƒæky s√∫ reprezentovan√© ako pole objektov. V oboch pr√≠padoch mi pri≈°lo najlep≈°ie indexova≈• textov√© polia ako `keyword`.

```json
{
    "conversation_references": {
        "type": "nested",
        "properties": {
            "id": { "type": "long" },
            "type": { "type": "keyword" },
            "author": {
                "properties": {
                    "id": { "type": "long" },
                    "name": { 
                        "type": "text",
                        "fields": {
                            "ngram": { "type": "text", "analyzer": "custom_ngram" },
                            "shingles": { "type": "text", "analyzer": "custom_shingles" }
                        } 
                    },
                    "username": { 
                        "type": "text",
                        "fields": {
                            "ngram": { "type": "text", "analyzer": "custom_ngram" }
                        }
                    }
                }
            },
            "content": { "type": "text", "analyzer": "englando" },
            "hashtags": {
                "properties":{
                    "tag": { "type": "text", "analyzer": "keyword_lowercase" }
                }
            }
        }
    }
}
```

*Fig. 9 Mapping pre d√°ta z tabuƒæky conversation_references*

Referencie s√∫ reprezentovan√© ako pole objetkov (tweetov), na ktor√© sa odkazuj√∫. Referencovan√© tweety maj√∫ vybran√© atrib√∫ty norm√°lnych tweetov (aj s rovnak√Ωmi typmi a indexovan√≠m) s t√Ωm, ≈æe e≈°te obsahuj√∫ typ referencie, ktor√Ω je indexovan√Ω ako `keyword`.

### Denormaliz√°cia

Keƒè≈æe je pri denormaliz√°ci√≠ potrebn√© joinova≈• veƒæk√© mno≈æstvo tabuliek, vytvoril som si pre zr√Ωchlenie danej query dodatoƒçn√© indexy pre v≈°etky cudzie kƒæ√∫ƒçe.

```sql
CREATE INDEX ca_conversation_id ON context_annotations(conversation_id);
CREATE INDEX ca_domain_id ON context_annotations(context_domain_id);
CREATE INDEX ca_entity_id ON context_annotations(context_entity_id);
CREATE INDEX h_conversation_id ON conversation_hashtags(conversation_id);
CREATE INDEX h_hashtag_id ON conversation_hashtags(hashtag_id);
CREATE INDEX an_conversation_id ON annotations(conversation_id);
CREATE INDEX l_conversation_id ON links(conversation_id);
CREATE INDEX cr_conversation_id ON conversation_references(conversation_id);
CREATE INDEX cr_parent_id ON conversation_references(parent_id);
```

*Fig. 10 SQL pre vytvorenie indexov pre cudzie kƒæ√∫ƒçe*

Pri denormaliz√°ci√≠ d√°t som postupne joinoval jednotliv√© tabuƒæky s tabuƒækou `conversations`. Kv√¥li lep≈°ej prehladnosti, ako aj n√°sledn√©mu importu d√°t do elasticu som sa rozhodol rovno ulo≈æi≈• d√°ta z ostatn√Ωch tabuliek ako json, na ƒço v postgrese sl√∫≈æia funkcie `to_json()` a `json_build_object()`.

Tabuƒæky, ktor√© pre dan√Ω tweet mohli vr√°ti≈• viac riadkov (v≈°etky okrem `authors`) boli kv√¥li jednoduch≈°ej agreg√°ci√≠ v√Ωsledkov e≈°te "zabalen√©" v subquery. Na agreg√°ciu som pou≈æil funkciu `json_agg()`, ktor√° tieto z√°znamy (json objekty) spoj√≠ do listu. Zauj√≠mavou ƒças≈•ou je subquery pre z√≠skanie referenci√≠ z tabuƒæky `conversation_references`, kde sa na z√≠skanie autora ako aj hashtagov parent tweetu pou≈æij√∫ samostatn√© subquery. Samotn√© query pre denormaliz√°ciu je na obr√°zku (Fig. 11)

```sql
SELECT 
	c.id, c."content", c.possibly_sensitive, c."language", c."source", c.retweet_count, c.reply_count, c.like_count, c.quote_count, c.created_at,
	to_json(a.*) author,
	COALESCE(ca.jsons, '[]') context_annotations,
	COALESCE(ch.jsons, '[]') conversation_hashtags,
	COALESCE(an.jsons, '[]') annotations,
	COALESCE(l.jsons, '[]') links,
	COALESCE(cr.jsons, '[]') conversation_references
FROM conversations c
JOIN authors a ON c.author_id = a.id
LEFT JOIN (
	SELECT ca.conversation_id, json_agg(json_build_object('entity', ce.*, 'domain', cd.*)) jsons
	FROM context_annotations ca
	JOIN context_entities ce ON ca.context_entity_id = ce.id
	JOIN context_domains cd ON ca.context_domain_id = cd.id 
	GROUP BY ca.conversation_id
) ca ON ca.conversation_id = c.id
LEFT JOIN (
	SELECT ch.conversation_id, json_agg(json_build_object('tag', h.tag)) jsons 
	FROM conversation_hashtags ch
	JOIN hashtags h ON ch.hashtag_id = h.id
	GROUP BY ch.conversation_id
) ch ON ch.conversation_id = c.id
LEFT JOIN (
	SELECT an.conversation_id, json_agg(json_build_object('value', an."value", 'probability', an.probability, 'type', an."type")) jsons 
	FROM annotations an
	GROUP BY an.conversation_id
) an ON an.conversation_id = c.id
LEFT JOIN (
	SELECT l.conversation_id, json_agg(json_build_object('url', l.url, 'title', l.title, 'description', l.description)) jsons 
	FROM links l
	GROUP BY l.conversation_id
) l ON l.conversation_id = c.id
LEFT JOIN (
	SELECT 
		cr.conversation_id,
		json_agg(json_build_object(
			'id', p.id, 'type', cr."type", 'content', p."content",
			'author', (
				SELECT json_build_object('id', pa.id, 'name', pa."name", 'username', pa.username) 
				FROM authors pa 
				WHERE pa.id = p.author_id
			),
			'hashtags', (
				SELECT json_agg(json_build_object('tag', h.tag)) 
				FROM conversation_hashtags ch 
				JOIN hashtags h ON ch.hashtag_id = h.id
				WHERE ch.conversation_id = p.id
			)
		)) jsons
	FROM conversation_references cr
	JOIN conversations p ON cr.parent_id = p.id
	GROUP BY cr.conversation_id
) cr ON cr.conversation_id = c.id;
```

*Fig. 11 SQL pre denormalizovanie tabuƒæky*

ƒéal≈°√≠m krokom by e≈°te mohlo by≈• vytvorenie novej tabuƒæky a tieto z√≠skan√© d√°ta do nej prida≈•, ƒço by n√°sledne zr√Ωchlilo samotn√Ω import d√°t do elasticu, keƒè≈æe by sa jednotliv√© riadky len vyberali z datab√°zy. Ja som, ale nemohol urobi≈• tento krok kv√¥li nedostatoƒçn√©mu voƒæn√©mu miestu.

## √öloha 4

Vlastn√© analyz√©ry a filtre sa daj√∫ ≈°pecifikova≈• pri vytv√°ran√≠ indexu. Analyz√©ry s√∫ vlastne definovan√© presne podƒæa zadania okrem `keyword_lowercase`, ktor√Ω sl√∫≈æi na indexovanie hashtagov v lowercase a ako `tokenizer` vyu≈æ√≠va `keyword`, keƒè≈æe hashtagy s√∫ aj tak zvyƒçajne len jeden v√Ωraz. Nastavenia indexu spolu s analyz√°tormi a filtrami sa nach√°dza v `src/config/settings.json`.

```json
{
    "analysis": {
        "analyzer": {
            "englando": {
                "type": "custom",
                "tokenizer": "standard",
                "char_filter": ["html_strip"],
                "filter": [
                    "english_possessive_stemmer",
                    "lowercase",
                    "english_stop",
                    "english_stemmer"
                ]
            },
            "custom_ngram": {
                "type": "custom",
                "tokenizer": "standard",
                "char_filter": ["html_strip"],
                "filter": [
                    "lowercase",
                    "asciifolding",
                    "filter_ngrams"
                ]
            },
            "custom_shingles": {
                "type": "custom",
                "tokenizer": "standard",
                "char_filter": ["html_strip"],
                "filter": [
                    "lowercase", 
                    "asciifolding",
                    "filter_shingles"
                ]
            },
            "keyword_lowercase": {
                "type": "custom",
                "tokenizer": "keyword",
                "filter": ["lowercase"]
            }
        },
    }
}
```

*Fig. 12 Definovanie vlastn√Ωch analyz√©rov*

Pri vytv√°ran√≠ analyz√©rov bolo taktie≈æ potrebn√© e≈°te dodefinova≈• filtre: `english_possessive_stemmer`, `english_stop`, `english_stemmer`, `filter_shingles` a `filter_ngrams`, ktor√© s√∫ na obr√°zku (Fig. 13).

```json
{
		"filter": {
            "filter_ngrams": {
                "type": "ngram",
                "min_gram": 1,
                "max_gram": 10
            },
            "filter_shingles": {
                "type": "shingle",
                "token_separator": ""
            },
            "english_possessive_stemmer": {
                "type": "stemmer",
                "language": "possessive_english"
            },
            "english_stop": {
                "type": "stop",
                "stopwords": "_english_"
            },
            "english_stemmer": {
                "type": "stemmer",
                "language": "english"
           }
       }
}
```

*Fig. 13 Definovanie vlastn√Ωch filtrov*

Pri `filter_ngrams` bolo potrebn√© e≈°te dodatoƒçne zmeni≈• nastavenie indexu pre `max_ngram_diff` na hodnotu `9`.

## √öloha 5

Pred samotn√Ωm importom je najsk√¥r potrebn√© vytvori≈• dan√Ω index a mapovanie, kde na vytvorenie a nastavenie indexu sl√∫≈æi napr. dopyt `PUT http://localhost:9200/tweets`, ktor√Ω m√° v body json obsahuj√∫ci nastavenia a ≈°pecifikovan√© analyz√©ry pre dan√Ω index. Mapping sa vytv√°ra podobne pomocou `PUT http://localhost:9200/tweets/_mapping`, kde je rovnako v body ≈°pecifikovan√Ω dan√Ω mapping. ƒéal≈°√≠a mo≈ænos≈• je vyu≈æi≈• elastic klient a mapping vytvori≈• rovno v skripte pomocou funkcie `es.indices.create(index, settings, mapping)`, do ktorej id√∫ ako parametre rovno objekty pre nastavenia a mapping. Ja som mapping vytv√°ral rovno v skripte vo funkci√≠ `create_mapping(es)`, z√°rove≈à sa json s√∫bory pre nastavenia a mapping nach√°dzaj√∫ v `src/config/settings.json` resp. `src/config/mapping.json`.

```python
es.indices.create(
	index=INDEX_NAME,
	settings=settings,
	mappings=mapping
)
```

*Fig. 14 Vytvorenie indexu pomocou python klienta*

D√°ta som do elasticu importoval pomocou python scriptu, ktor√©ho hlavn√° ƒças≈• sa nach√°dza v `src/main.py`. Import pozost√°va hlavne z vyberania d√°t z postgresql a ich n√°sledn√©mu importovaniu do elasticu.

Pre samotn√© importovanie sl√∫≈æi funkcia `import_data(conn, es, data_size)`, ktor√° sa sklad√° z dvoch hlavn√Ωch cyklov, kde prv√Ω cyklus sl√∫≈æi na samotn√© vyberanie d√°t z datab√°zy.

```python
while True: 
    cur = query_data(conn, last_id, limit)
    data = []
    
    while True:
        rows = cur.fetchmany(batch_size)
        if len(rows) == 0:  break

        for row in rows:
            header = {'index': {'_index': INDEX_NAME, '_id': row['id']}}
            data.extend([header, row])
                processed_rows += 1
        last_id = header['index']['_id']
        
        es.bulk(index=INDEX_NAME, operations=data)
        data.clear()

        total_processed_rows += processed_rows
    cur.close()

    if processed_rows == 0 or total_processed_rows >= data_size:
        break
```

*Fig. 15 Hlavn√° ƒças≈• importovania d√°t z funkcie import_data()*

Keƒè≈æe tabuƒæka `conversations` obsahuje pribli≈æne 32 mili√≥nov riadkov, nie je veƒæmi efekt√≠vne ich vybra≈• v≈°etky naraz, preto sa d√°ta vyberaj√∫ vo viacer√Ωch skupin√°ch podƒæa urƒçen√©ho limitu, ktor√Ω bol nastaven√Ω na 8 mili√≥nov. Na zaƒçiatku cyklu sa v≈ædy zavol√° funkcia `query_data(conn, last_id, limit)`, ktor√° v podstate len vytvor√≠ server cursor a vykon√° query z Fig. 11 spolu s dan√Ωm limitom a podmienkou `WHERE c.id > {last_id}`, ktor√° zais≈•uje, ≈æe ƒèal≈°ia d√°vka, alebo skupina, bude obsahova≈• iba riadky, ktor√© s√∫ v tabuƒæke ƒèalej ako posledn√Ω importovan√Ω riadok, ktor√©ho id = `last_id`.

Druh√Ω cyklus u≈æ sl√∫≈æi na importovanie d√°t do elasticu po urƒçen√Ωch d√°vkach (v mojom pr√≠pade po 200 riadkoch). V cykle sa najsk√¥r pomocou `cur.fetchmany(batch_size)` vyberie d√°vka dokumentov, cez ktor√∫ je potrebn√© prejs≈• a pripravi≈• d√°ta pre bulk import. V elasticu mus√≠ by≈• pri bulk importe pred samotn√Ωm dokumentom e≈°te jeden riadok (`header`), ktor√Ω opisuje ak√° akcia sa m√° vykona≈• (`'index'`), v ktorom indexe (`'_index'`) a id dan√©ho dokumentu (`_id`), ktor√© je v na≈°om pr√≠pade rovnak√© ako id tweetu v datab√°ze. Nakoniec sa vykon√° samotn√Ω import pomocou `es.bulk(index_name, data)` a cyklus sa zopakuje.

Moja met√≥da, ale nie je veƒæmi efekt√≠vna. Urƒçite by sa dala zlep≈°i≈• napr. pomocou paraleliz√°cie dopytov do postgresu a n√°sledn√©ho importovania do elasticu. Kedy by mohlo niekoƒæko threadov s√∫ƒçastne vybera≈• in√© d√°vky dokumentov, ƒç√≠m by sa skr√°tilo ƒçakanie na vybratie ƒèal≈°ej skupiny (`WHERE` podmienka), ktor√© sa ƒçasom e≈°te predl≈æuje.

Uk√°≈æka za-indexovan√©ho dokumentu sa nach√°dza aj v `docs/sample_document.json`.

```python
{
    "_index": "tweets",
    "_id": "1497032529894805509",
    "_score": null,
    "_source": {
        "id": 1497032529894805509,
        "content": "RT @one_sorrow: SPREAD AND SHARE, YOU CAN HELP UKRAINE #Ukraine #Russia https://t.co/rp2IFCKMi3",
        "possibly_sensitive": false,
        "language": "en",
        "source": "Twitter for Android",
        "retweet_count": 6085,
        "reply_count": 0,
        "like_count": 0,
        "quote_count": 0,
        "created_at": "2022-02-25T03:15:43+01:00",
        "author": {
            "id": 1409764954845159428,
            "name": "ted | wil | alex",
            "username": "michaelkinnie",
            "description": "‚òÖthey/he/it/xey‚òÖ\n‚òÖqueer and nonbinary‚òÖ\n‚òÖted nivison, wilbur soot, & alex kralie irl (srs)‚òÖ",
            "followers_count": 9,
            "following_count": 126,
            "tweet_count": 1181,
            "listed_count": 0
        },
        "context_annotations": [
            {
                "entity": {
                    "id": 1484601166080081920,
                    "name": "Russo-Ukrainian conflict",
                    "description": null
                },
                "domain": {
                    "id": 123,
                    "name": "Ongoing News Story",
                    "description": "Ongoing News Stories like 'Brexit'"
                }
            },
            {
                "entity": {
                    "id": 1484601166080081920,
                    "name": "Russo-Ukrainian conflict",
                    "description": null
                },
                "domain": {
                    "id": 123,
                    "name": "Ongoing News Story",
                    "description": "Ongoing News Stories like 'Brexit'"
                }
            }
        ],
        "conversation_hashtags": [
            {
                "tag": "Ukraine"
            },
            {
                "tag": "Russia"
            }
        ],
        "annotations": [
            {
                "value": "UKRAINE",
                "probability": 0.954,
                "type": "Place"
            }
        ],
        "links": [
            {
                "url": "https://twitter.com/one_sorrow/status/1496727690157588483/photo/1",
                "title": null,
                "description": null
            }
        ],
        "conversation_references": [
            {
                "id": 1496727690157588483,
                "type": "retweeted",
                "content": "SPREAD AND SHARE, YOU CAN HELP UKRAINE #Ukraine #Russia https://t.co/rp2IFCKMi3",
                "author": {
                    "id": 1068701541979185155,
                    "name": "One for Pocskie",
                    "username": "one_sorrow"
                },
                "hashtags": [
                    {
                        "tag": "Ukraine"
                    },
                    {
                        "tag": "Russia"
                    }
                ]
            }
        ]
    }
}
```

*Fig. 16 Uk√°≈æka zaindexovan√©ho dokumentu*

## √öloha 6

Na importovanie prv√Ωch 5000 z√°znamov do elasticu staƒç√≠ len zavola≈• funkciu `import_data(conn, es, data_size)` s `data_size=5000`. Cel√Ω import trval okolo 2s a fin√°lny poƒçet dokumentov sa d√° napr. overi≈• pomocou jednoduch√©ho vyhƒæad√°vania, ktor√© vr√°ti v≈°etky zaindexovan√© dokumenty.

```javascript
{
	"query": {
		"match_all": {}
	}
}
```

*Fig. 17 Query pre n√°jdenie v≈°etk√Ωch dokumentov*

T√°to query naozaj n√°jde 5000 dokumentov:

![SniÃÅmka obrazovky 2022-12-22 o 22.20.16.png](https://res.craft.do/user/full/c3363b00-79de-4d25-d963-64ad0ea4e431/doc/32937CFC-697F-4DE2-9614-1C7ABB585F4F/4FB6E7F1-1F28-4122-9E9A-F4C2695F0AC4_2/yuyJaYxxNbqgGVZkkE3SwLN7IQcEO9J8jvpOcbuNZRMz/Snimka%20obrazovky%202022-12-22%20o%2022.20.16.png)

*Fig. 18 V√Ωsledok z vyhƒæad√°vania v≈°etk√Ωch dokumentov*

## √öloha 7

![SniÃÅmka obrazovky 2022-12-22 o 20.31.40.png](https://res.craft.do/user/full/c3363b00-79de-4d25-d963-64ad0ea4e431/doc/32937CFC-697F-4DE2-9614-1C7ABB585F4F/809B99D7-6733-4024-89DD-48F0CDFEC47A_2/H500rvyi3Pi3XKMRyhR0B6npW1vQsFykaFGcFDFZ0iMz/Snimka%20obrazovky%202022-12-22%20o%2020.31.40.png)

*Fig. 19 P√¥vodne usporiadanie nodov*

Na zaƒçiatku je node `es02` nastaven√Ω ako master. Ak ho zastav√≠m pomocou `docker stop elastic-es02-1`, zvol√≠ sa nov√Ω master (v tomto pr√≠pade `es01`) a v≈°etky shardy sa prerozdelia na zvy≈°n√© nody.

![SniÃÅmka obrazovky 2022-12-22 o 20.33.42.png](https://res.craft.do/user/full/c3363b00-79de-4d25-d963-64ad0ea4e431/doc/32937CFC-697F-4DE2-9614-1C7ABB585F4F/4BA7DFF8-A3AA-4972-9B25-718218283F4A_2/pgxvFxslLQlJgvDuvUQSAsOHRO0NL9V9f7ZvyZHQiqYz/Snimka%20obrazovky%202022-12-22%20o%2020.33.42.png)

![SniÃÅmka obrazovky 2022-12-22 o 20.37.19.png](https://res.craft.do/user/full/c3363b00-79de-4d25-d963-64ad0ea4e431/doc/32937CFC-697F-4DE2-9614-1C7ABB585F4F/4B83B0B8-F20E-42DD-8126-D80B03D4AD17_2/SGzWRZ03tnS2M0m35ubmfb4EcMnl7jinQgHcxS1FYkMz/Snimka%20obrazovky%202022-12-22%20o%2020.37.19.png)

*Fig. 20 Nov√© usporiadanie nodov a shardov*

V tomto rozdelen√≠ je taktie≈æ e≈°te mo≈æn√© prid√°va≈•, prehƒæad√°va≈• a maza≈• dokumenty.

![SniÃÅmka obrazovky 2022-12-22 o 20.46.06.png](https://res.craft.do/user/full/c3363b00-79de-4d25-d963-64ad0ea4e431/doc/32937CFC-697F-4DE2-9614-1C7ABB585F4F/49CDD9F2-0414-4014-B454-8BC58E4ACA88_2/mW7KDgRTHNVS8m1KxExxGEdMvAT7UZb2zYtuybtcoVsz/Snimka%20obrazovky%202022-12-22%20o%2020.46.06.png)

![SniÃÅmka obrazovky 2022-12-22 o 20.45.54.png](https://res.craft.do/user/full/c3363b00-79de-4d25-d963-64ad0ea4e431/doc/32937CFC-697F-4DE2-9614-1C7ABB585F4F/B6B53872-4535-4586-AC42-C42773AF2C77_2/7frwEGcb0mVn7juHjthrMtV2Ltwxjx3L5ZlqtMZx1Zwz/Snimka%20obrazovky%202022-12-22%20o%2020.45.54.png)

![SniÃÅmka obrazovky 2022-12-22 o 20.47.14.png](https://res.craft.do/user/full/c3363b00-79de-4d25-d963-64ad0ea4e431/doc/32937CFC-697F-4DE2-9614-1C7ABB585F4F/8B520E8F-F152-4788-B24A-CCDA04B68E07_2/moWNbpWeJ7KGbcvlE3hxkmOhzkl8y3TCGFDktpsesi4z/Snimka%20obrazovky%202022-12-22%20o%2020.47.14.png)

*Fig. 21 V√Ωsledok prid√°vania, prehƒæad√°vania a mazania po vypnut√≠ jedn√©ho nodu*

Ak ale vypnem aj node `es03`, kluster prestane fungova≈•. Toto je sp√¥soben√© t√Ωm, ≈æe klaster u≈æ neobsahuje dostatoƒçn√© mno≈æstvo nodov (mala by by≈• dostupn√° nadpoloviƒçn√° v√§ƒç≈°ina "master-eligible" nodov), ktor√© sa m√¥≈æu sta≈• masterom a nedok√°≈æe sa zvoli≈• nov√Ω master.

Elasticsearch sa d√° nastavi≈• aj tak aby tvoril klaster len jeden node, na ƒço sl√∫≈æi configur√°cia `discovery.type=single-node`. Toto nastavenie, ale nie je odpor√∫ƒçan√© pre komerƒçn√© aplik√°cie. Tak√Ωto klaster s jedn√Ωm nodom nie je odoln√Ω, keƒè≈æe ak tento node zlyh√°, cel√° aplik√°cia prestane fungova≈• - ƒço je aj jedn√Ωm z d√¥vodov preƒço tak√©to kv√≥rum existuje.

## √öloha 8

Na zaƒçiatku m√° dokument `"_seq_no": 1687` a `"_primary_term": 1`.

![SniÃÅmka obrazovky 2022-12-22 o 23.02.00.png](https://res.craft.do/user/full/c3363b00-79de-4d25-d963-64ad0ea4e431/doc/32937CFC-697F-4DE2-9614-1C7ABB585F4F/99BAAACE-AE23-42F9-8292-15695881C8C2_2/Ekpfs6hbpdUslo01pY4NsyXYFIoNEf5DYM3hdR1yXjEz/Snimka%20obrazovky%202022-12-22%20o%2023.02.00.png)

*Fig. 22 P√¥vodn√Ω stav dokument*

Ak pomocou `POST http://localhost:9200/tweets/_update/1082538033130414080` uprav√≠m hodnotu `"retweet_count"`, zmen√≠ sa len `"_seq_no": 1687`, ktor√© odzrkadluje poƒçet zmien samotn√©ho dokumentu. Teda, ak pomocou nasledovn√©ho skriptu:

```json
{
  "script": {
    "source": "ctx._source.retweet_count += params.number_of_retweets",
    "params": {
      "number_of_retweets": 2
    }
  }
}
```

*Fig. 23 Skript na √∫pravu dokumentu*

≈°tyrikr√°t zmen√≠m poƒçet retweetov, `_seq_no` sa zv√Ω≈°i o 4.

![SniÃÅmka obrazovky 2022-12-22 o 23.12.23.png](https://res.craft.do/user/full/c3363b00-79de-4d25-d963-64ad0ea4e431/doc/32937CFC-697F-4DE2-9614-1C7ABB585F4F/815B4252-870B-496F-88C7-9BD69D967A92_2/Mw6uKZGknoVi3kCvUksEyE6wQLR4oWqNuM5CprbnEd0z/Snimka%20obrazovky%202022-12-22%20o%2023.12.23.png)

*Fig. 24 Dokument po zv√Ω≈°en√≠ retweetov*

Ak zru≈°√≠m node `es03`, na ktorom sa nach√°dza shard s dan√Ωm dokumentom (kde je ulo≈æen√Ω dan√Ω dokument sa d√° zisti≈• pomocou `"analyse": true`), zv√Ω≈°i sa aj `"_primary_term"`, ktor√Ω vlastne hovor√≠ koƒækokr√°t sa zmenil prim√°rny shard dan√©ho dokumentu. Teda v tomto pr√≠pade sa z repliky shardu, na ktorom bol dan√Ω dokument stal nov√Ω prim√°rny shard.

![SniÃÅmka obrazovky 2022-12-22 o 23.33.21.png](https://res.craft.do/user/full/c3363b00-79de-4d25-d963-64ad0ea4e431/doc/32937CFC-697F-4DE2-9614-1C7ABB585F4F/88E7CBDD-0B58-4BE3-9C98-E82D4E42C592_2/BiFtyJYKD3NQZuZ6MTFUtJ0GEXWu8G1Jv2xejkP45vQz/Snimka%20obrazovky%202022-12-22%20o%2023.33.21.png)

*Fig. 25 Dokument po vypnut√≠ nodu `es03`*

Ak by som spustil node `es03` a zas zru≈°il node `es01`, na ktorom sa dokument nach√°dza tentokr√°t, hodnota `"_primary_term"` by sa znovu zv√Ω≈°ila.

![SniÃÅmka obrazovky 2022-12-22 o 23.46.18.png](https://res.craft.do/user/full/c3363b00-79de-4d25-d963-64ad0ea4e431/doc/32937CFC-697F-4DE2-9614-1C7ABB585F4F/482B74B5-7E4D-4EEB-B509-2F4E34BE93F9_2/od8SSS0lBclMOOA1XnBnNrtWK78mbczBMy9Drvplq0wz/Snimka%20obrazovky%202022-12-22%20o%2023.46.18.png)

*Fig. 26 Dokument po vypnut√≠ nodu `es01`*

Tieto hodnoty sl√∫≈æia na sledovanie zmien dokumentov, kedy napr. v pr√≠pade v√Ωpadku jedn√©ho zo shardov zabezpeƒçuj√∫, ≈æe shard a jeho repliky maj√∫ rovnak√∫ (najaktu√°lnej≈°iu) verziu dan√©ho dokumentu a zabezpeƒçuj√∫ r√Ωchlej≈°ie zotavenie shardu po jeho v√Ωpatku.

## √öloha 9

V tejto √∫lohe je najsk√¥r potrebn√© vymaza≈• index na ƒço sl√∫≈æi dopyt `DELETE http://localhost:9200/tweets` alebo pomocou elastic klienta pre python a funkcie `es.indices.delete(index='tweets')`.

Pre odstr√°nenie repl√≠k staƒç√≠ len prep√≠sa≈• v nastaveniach indexu (Fig. 2) `"number_of_replicas"` na `0`. Oproti importovaniu 5000 z√°znamov je v tomto pr√≠pade potrebn√© v skripte nastavi≈• veƒækos≈• d√°t (`data_size`) na `-1`, kedy sa naiportuje cel√° datab√°za:

```python
import_data(conn, es, data_size)
```

Pre prv√Ωch 8 mili√≥nov dokumentov bol skript pomerne r√Ωchly a dok√°zal importova≈• 10000 dokumentov za pribli≈æne 4s. Probl√©m, ale nastal po prekroƒçen√≠ 2 mili√≥nov, kedy elastic zaƒçal hl√°si≈• chybu s voƒæn√Ωm miestom. Tento probl√©m sa mi nepodarilo vyrie≈°i≈•, ale najsk√¥r bude chyba s nastaven√≠m elastic klastera alebo samotn√©ho dockera, preto≈æe v tomto momente e≈°te bolo voƒæn√© miesto na SSD, a taktie≈æ nemohol by≈• probl√©m v nedostatku RAM.

Nakoniec sa mi podarilo naimportova≈• len 2 691 600 dokumentov. Poƒçet dokumentov sa d√° pozrie≈• pomocou `GET http://localhost:9200/tweets/_count`.

![SniÃÅmka obrazovky 2022-12-24 o 15.10.27.png](https://res.craft.do/user/full/c3363b00-79de-4d25-d963-64ad0ea4e431/doc/A7CCD4DF-2005-43F1-AA3E-6F7A912195D1/905BE4DE-C348-4754-86C7-A3F105A81368_2/3SmOfG52ZzCqlFXNkFKdyRfNY7yOXzLeSjKTQ4Nh9N0z/Snimka%20obrazovky%202022-12-24%20o%2015.10.27.png)

*Fig. 27 Poƒçet naimportovan√Ωch dokumentov*

## √öloha 10

T√∫to √∫lohu som nestihol üòï

